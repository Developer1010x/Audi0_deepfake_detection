{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1XWSTcNlwvvnpPdxp-m30ariBYkzaeMh3","authorship_tag":"ABX9TyPosRiuKeAz38TCMiHqomKq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n","\n","!pip install unrar\n","!unrar x /content/drive/MyDrive/data.rar\n","\n","\n","\n","\n","import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import to_categorical\n","# Constants\n","DATASET_PATH = \"/content/data\"\n","NUM_CLASSES = 2  # Assuming there are two classes, you can adjust this based on your folder structure\n","SAMPLE_RATE = 16000\n","DURATION = 5\n","N_MELS = 128\n","max_time_steps = 109\n","# Dynamically generate labels based on folder names\n","labels = {}\n","class_index = 0\n","\n","for root, dirs, files in os.walk(DATASET_PATH):\n","    for folder in dirs:\n","        folder_path = os.path.join(root, folder)\n","\n","        # Assuming each folder is a class, you may need to adjust this based on your specific dataset structure\n","        labels[folder] = class_index\n","        class_index += 1\n","\n","# Load audio data and labels\n","X = []\n","y = []\n","\n","for root, dirs, files in os.walk(DATASET_PATH):\n","    for file_name in files:\n","        file_path = os.path.join(root, file_name)\n","\n","        audio, _ = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)\n","\n","        mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=SAMPLE_RATE, n_mels=N_MELS)\n","        mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n","\n","        if mel_spectrogram.shape[1] < max_time_steps:\n","            mel_spectrogram = np.pad(mel_spectrogram, ((0, 0), (0, max_time_steps - mel_spectrogram.shape[1])), mode='constant')\n","        else:\n","            mel_spectrogram = mel_spectrogram[:, :max_time_steps]\n","\n","        X.append(mel_spectrogram)\n","        # Extract label from the folder name\n","        label = labels[root.split(\"/\")[-1]]  # Adjust this based on your specific folder structure\n","        y.append(label)\n","\n","# Convert to numpy arrays\n","X = np.array(X)\n","y = np.array(y)\n","\n","# One-hot encode labels\n","y_encoded = to_categorical(y, NUM_CLASSES)\n","\n","# Split the data into training and validation sets\n","split_index = int(0.8 * len(X))\n","X_train, X_val = X[:split_index], X[split_index:]\n","y_train, y_val = y_encoded[:split_index], y_encoded[split_index:]"],"metadata":{"id":"I8ppURjMFChP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Define the model\n","model_input = Input(shape=(N_MELS, max_time_steps, 1))\n","x = Conv2D(32, kernel_size=(3, 3), activation='relu')(model_input)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","x = Conv2D(64, kernel_size=(3, 3), activation='relu')(x)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","x = Flatten()(x)\n","x = Dense(128, activation='relu')(x)\n","x = Dropout(0.5)(x)\n","model_output = Dense(NUM_CLASSES, activation='softmax')(x)\n","\n","# Compile the model\n","model = Model(inputs=model_input, outputs=model_output)\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","\n","model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_val, y_val))\n","\n","# Save the model\n","model.save(\"Deepfake_audio.h5\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HwePbCLdFTPH","executionInfo":{"status":"ok","timestamp":1705122690879,"user_tz":-330,"elapsed":78973,"user":{"displayName":"S PRAJWALL NARAYANA","userId":"08026130868064420267"}},"outputId":"49ba1320-36d1-4628-8fcd-790da3275c01"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","500/500 [==============================] - 14s 14ms/step - loss: 2.2868 - accuracy: 0.6212 - val_loss: 0.9814 - val_accuracy: 0.0000e+00\n","Epoch 2/10\n","500/500 [==============================] - 7s 14ms/step - loss: 0.6621 - accuracy: 0.6248 - val_loss: 1.0061 - val_accuracy: 0.0000e+00\n","Epoch 3/10\n","500/500 [==============================] - 7s 14ms/step - loss: 0.6624 - accuracy: 0.6250 - val_loss: 0.9714 - val_accuracy: 0.0000e+00\n","Epoch 4/10\n","500/500 [==============================] - 7s 13ms/step - loss: 0.6624 - accuracy: 0.6249 - val_loss: 0.9723 - val_accuracy: 0.0000e+00\n","Epoch 5/10\n","500/500 [==============================] - 7s 14ms/step - loss: 0.6621 - accuracy: 0.6250 - val_loss: 0.9761 - val_accuracy: 0.0000e+00\n","Epoch 6/10\n","500/500 [==============================] - 7s 13ms/step - loss: 0.6622 - accuracy: 0.6250 - val_loss: 0.9772 - val_accuracy: 0.0000e+00\n","Epoch 7/10\n","500/500 [==============================] - 7s 14ms/step - loss: 0.6620 - accuracy: 0.6250 - val_loss: 0.9797 - val_accuracy: 0.0000e+00\n","Epoch 8/10\n","500/500 [==============================] - 6s 13ms/step - loss: 0.6619 - accuracy: 0.6250 - val_loss: 1.0064 - val_accuracy: 0.0000e+00\n","Epoch 9/10\n","500/500 [==============================] - 7s 14ms/step - loss: 0.6621 - accuracy: 0.6251 - val_loss: 0.9581 - val_accuracy: 0.0000e+00\n","Epoch 10/10\n","500/500 [==============================] - 7s 13ms/step - loss: 0.6620 - accuracy: 0.6250 - val_loss: 0.9688 - val_accuracy: 0.0000e+00\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","\n","# Define paths and parameters\n","TEST_DATASET_PATH = \"/content/Test\"\n","MODEL_PATH = \"Deepfake_audio.h5\"  # Replace with the actual path to your saved model\n","SAMPLE_RATE = 16000\n","DURATION = 5\n","N_MELS = 128\n","MAX_TIME_STEPS = 109\n","\n","# Load the saved model\n","model = load_model(MODEL_PATH)\n","\n","# Load and preprocess test data using librosa\n","X_test = []\n","\n","test_files = os.listdir(TEST_DATASET_PATH)\n","for file_name in test_files:\n","    file_path = os.path.join(TEST_DATASET_PATH, file_name)\n","\n","    try:\n","        # Check if the file is an audio file (skip non-audio files)\n","        if not file_name.endswith(('.wav', '.mp3', '.flac')):\n","            continue\n","\n","        # Load audio file using librosa\n","        audio, _ = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)\n","\n","        # Extract Mel spectrogram using librosa\n","        mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=SAMPLE_RATE, n_mels=N_MELS)\n","        mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n","\n","        # Ensure all spectrograms have the same width (time steps)\n","        if mel_spectrogram.shape[1] < MAX_TIME_STEPS:\n","            mel_spectrogram = np.pad(mel_spectrogram, ((0, 0), (0, MAX_TIME_STEPS - mel_spectrogram.shape[1])), mode='constant')\n","        else:\n","            mel_spectrogram = mel_spectrogram[:, :MAX_TIME_STEPS]\n","\n","        X_test.append(mel_spectrogram)\n","    except Exception as e:\n","        print(f\"Error processing file {file_name}: {e}\")\n","\n","# Convert list to numpy array\n","X_test = np.array(X_test)\n","\n","# Predict using the loaded model\n","y_pred = model.predict(X_test)\n","\n","# Convert probabilities to predicted classes\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","\n","# Print the predicted classes\n","print(\"Predicted classes:\", y_pred_classes)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2E48NoCQ6qs","executionInfo":{"status":"ok","timestamp":1705123633061,"user_tz":-330,"elapsed":832,"user":{"displayName":"S PRAJWALL NARAYANA","userId":"08026130868064420267"}},"outputId":"73f42ab8-141c-4f12-b72f-109b0e5a6280"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 87ms/step\n","Predicted classes: [0 1 0 0 0 1 1 1 1 0]\n"]}]}]}